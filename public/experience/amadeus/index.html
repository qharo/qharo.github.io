<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>RF-Based Automatic Prompt Compression &middot; Aditya Yogesh Nair</title>
  <meta name="title" content="RF-Based Automatic Prompt Compression &middot; Aditya Yogesh Nair" />
  
  <meta name="description" content="Amadeus Research Team (ART)" />
  <meta name="keywords" content="NLP, PyTorch, Internship, " />
  
  
  <link rel="canonical" href="http://localhost:1313/experience/amadeus/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.7e511937ade47127f0cc4d4943b7cc62b8f7cf37a9c19383694c5760ad479781345dbedf1b713a57a80254844a8966c81cb86298461c8f60c196036e053f9605.css"
    integrity="sha512-flEZN63kcSfwzE1JQ7fMYrj3zzepwZODaUxXYK1Hl4E0Xb7fG3E6V6gCVIRKiWbIHLhimEYcj2DBlgNuBT&#43;WBQ==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.38829a2d46667b3048ed12a339f7a49584d39596241b4e61e344c689c257fec016f6e18ea8a349c0a7e2b35a3ef0ab2aed556a64100ada730fc9666da5b7c29a.js"
    integrity="sha512-OIKaLUZmezBI7RKjOfeklYTTlZYkG05h40TGicJX/sAW9uGOqKNJwKfis1o&#43;8Ksq7VVqZBAK2nMPyWZtpbfCmg==" data-copy="" data-copied=""></script>
  
  
  
  <script src="/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js" integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S&#43;Yti0U7QtuZvQ=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/experience/amadeus/">
  <meta property="og:site_name" content="Aditya Yogesh Nair">
  <meta property="og:title" content="RF-Based Automatic Prompt Compression">
  <meta property="og:description" content="Amadeus Research Team (ART)">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="experience">
    <meta property="article:published_time" content="2024-09-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-09-01T00:00:00+00:00">
    <meta property="article:tag" content="NLP">
    <meta property="article:tag" content="PyTorch">
    <meta property="article:tag" content="Internship">
    <meta property="og:image" content="http://localhost:1313/experience/amadeus/thumbnail.png">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/experience/amadeus/thumbnail.png">
  <meta name="twitter:title" content="RF-Based Automatic Prompt Compression">
  <meta name="twitter:description" content="Amadeus Research Team (ART)">

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Experience",
    "name": "RF-Based Automatic Prompt Compression",
    "headline": "RF-Based Automatic Prompt Compression",
    
    "abstract": "Amadeus Research Team (ART)",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/experience\/amadeus\/",
    "author" : {
      "@type": "Person",
      "name": "Aditya Yogesh Nair"
    },
    "copyrightYear": "2024",
    "dateCreated": "2024-09-01T00:00:00\u002b00:00",
    "datePublished": "2024-09-01T00:00:00\u002b00:00",
    
    "dateModified": "2024-09-01T00:00:00\u002b00:00",
    
    "keywords": ["NLP","PyTorch","Internship"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1232"
  }]
  </script>


  
  
  <meta name="author" content="Aditya Yogesh Nair" />
  
  
  
  <link href="https://github.com/qharo" rel="me" />
  
  
  <link href="https://linkedin.com/in/aditya-y-nair" rel="me" />
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>











<link type="text/css" rel="stylesheet" href="/lib/katex/katex.min.68e17230ccd917b97b7a2def38a8108918599d8aa4f580bfb8cce5e13d23e4de43dcaba5f9000553cb2c10d0d1300aabfe5c433a3305ebd752609f0762a63e59.css" integrity="sha512-aOFyMMzZF7l7ei3vOKgQiRhZnYqk9YC/uMzl4T0j5N5D3Kul&#43;QAFU8ssENDRMAqr/lxDOjMF69dSYJ8HYqY&#43;WQ==" />


<script defer src="/lib/katex/katex.min.50f14e69d6a8da7128ae3b63974c544ed377c36d096b5e3750f114e84c89d668b9301d9b0ed3248969aa183aa2e3bc4d2c1e73d5dcb7d462890c45a18d424589.js" integrity="sha512-UPFOadao2nEorjtjl0xUTtN3w20Ja143UPEU6EyJ1mi5MB2bDtMkiWmqGDqi47xNLB5z1dy31GKJDEWhjUJFiQ=="></script>


<script defer src="/lib/katex/auto-render.min.6095714e3aadb63b14ddc4af69346ab12974c1b460654345f8d1860a0b68fcc51b22f68b757433193090bb80afc8965b65cb607e5541d0f5f0f4b2e64d69b9ff.js" integrity="sha512-YJVxTjqttjsU3cSvaTRqsSl0wbRgZUNF&#43;NGGCgto/MUbIvaLdXQzGTCQu4CvyJZbZctgflVB0PXw9LLmTWm5/w=="
  onload="renderMathInElement(document.body);"></script>








































































































































  
  



  
  
  <meta name="theme-color"/>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom bg-neutral dark:bg-neutral-800"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">Aditya Yogesh Nair</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
            
  <a href="https://raw.githubusercontent.com/qharo/qharo.github.io/main/static/files/Resume.pdf"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <span  class="mr-1" >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path fill="currentColor" d="M288 32c0-17.7-14.3-32-32-32s-32 14.3-32 32V274.7l-73.4-73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0l128-128c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L288 274.7V32zM64 352c-35.3 0-64 28.7-64 64v32c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V416c0-35.3-28.7-64-64-64H346.5l-45.3 45.3c-25 25-65.5 25-90.5 0L165.5 352H64zM432 456c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg>
  </span>


    </span>
    
    <p class="text-base font-medium" title="">
        Resume
    </p>
</a>



            
            

            


            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                    
  <li class="mt-1">
    <a href="https://raw.githubusercontent.com/qharo/qharo.github.io/main/static/files/Resume.pdf"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <div  class="mr-2" >
            

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path fill="currentColor" d="M288 32c0-17.7-14.3-32-32-32s-32 14.3-32 32V274.7l-73.4-73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0l128-128c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L288 274.7V32zM64 352c-35.3 0-64 28.7-64 64v32c0 35.3 28.7 64 64 64H448c35.3 0 64-28.7 64-64V416c0-35.3-28.7-64-64-64H346.5l-45.3 45.3c-25 25-65.5 25-90.5 0L165.5 352H64zM432 456c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg>
  </span>


        </div>
        
        <p class="text-bg font-bg" title="">
            Resume
        </p>
    </a>
</li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>





  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/"
      >Aditya Yogesh Nair</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline ">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/experience/"
      >Experience</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/experience/amadeus/"
      >RF-Based Automatic Prompt Compression</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      RF-Based Automatic Prompt Compression
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  



















<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-09-01T00:00:00&#43;00:00">1 September 2024</time>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/nlp/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    NLP
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/pytorch/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    PyTorch
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/internship/&#34;,'_self');">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Internship
  </span>
</span>
  </span>
  
  
  
  
</div>




    </div>

    
    
    
    
    

    

    
      
      

      

      

    

  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
    

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          <div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl">
  While current state-of-the-art prompt compression methods rely on large neural networks or manual prompt engineering, this research proposes a lightweight alternative that leverages attention mechanisms inherent in transformer models. By extracting statistical features from attention vectors and training a Random Forest classifier, the approach achieves comparable performance to existing methods for a fraction of the inference cost and nearly no training cost. This makes the method particularly suitable for real-time context history compression in API-based LLM applications.
</div>



<h2 class="relative group">Transformers 
    <div id="transformers" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#transformers" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p><a href="https://arxiv.org/pdf/1706.03762" target="_blank">Transformer architecture</a> revolutionized natural language processing through its self-attention mechanism, which allows tokens to dynamically influence each other&rsquo;s representations. This attention mechanism computes relevance between queries and keys, applying the resulting weights to values, enabling the model to capture complex relationships and dependencies in text.</p>


<h4 class="relative group">Increasing Computational Demand 
    <div id="increasing-computational-demand" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#increasing-computational-demand" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>This success has led to increasingly resource-intensive models, with sizes growing from BERT&rsquo;s 110M parameters to GPT-3&rsquo;s 175B and beyond. Context lengths have similarly expanded, from 512 tokens to over 1M tokens in models like Claude. This growth has significantly increased computational requirements, as attention mechanisms scale quadratically with context length.</p>


<h4 class="relative group">API Alternative 
    <div id="api-alternative" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#api-alternative" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p>While this trend has pushed most organizations toward API-based solutions as a more convenient and cost-effective alternative to in-house development, it introduces new challenges around token usage, blackbox functioning and computational overhead.</p>


<h2 class="relative group">Prompt Compression 
    <div id="prompt-compression" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#prompt-compression" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Prompt compression techniques fall into two main categories:</p>
<ul>
<li><strong>Abstractive</strong> compression generates new, condensed versions of prompts, potentially using tokens not present in the original input. While this approach offers greater flexibility and potential for creative compression, it tends to be computationally intensive and risks semantic drift from the original content.</li>
<li><strong>Extractive</strong> compression, conversely, selects and retains tokens from the original input. Though more constrained in its approach, it offers faster computation and better preservation of original meaning, making it particularly suitable for maintaining semantic fidelity in compressed prompts.</li>
</ul>


<h4 class="relative group">LLMLingua 1 
    <div id="llmlingua-1" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#llmlingua-1" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p><a href="https://aclanthology.org/2023.emnlp-main.825.pdf" target="_blank">LLMLingua 1</a> introduced a two-step prompt compression framework based on perplexity optimization. The system first dynamically allocates compression ratios across prompt components (sentences, examples, etc.) based on user-defined targets. It then performs finer-grained optimization at the token level, leveraging the key insight that higher perplexity indicates more informative content. The framework utilized an Alpaca 7B model, requiring distribution alignment with target models, but demonstrated impressive results with up to 20x compression while maintaining prompt response quality.</p>


<h4 class="relative group">LLMLingua 2 
    <div id="llmlingua-2" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#llmlingua-2" aria-label="Anchor">#</a>
    </span>        
    
</h4>
<p><a href="https://aclanthology.org/2024.findings-acl.57.pdf" target="_blank">LLMLingua 2</a> addresses key limitations of its predecessor, particularly the reliance on a large aligned model and unidirectional attention constraints. It employs GPT-4 to create a high-quality token-labeled dataset, training a transformer encoder (<a href="https://huggingface.co/microsoft/llmlingua-2-xlm-roberta-large-meetingbank" target="_blank">xlm-roberta</a> with approximately 355M parameters) for token classification. This approach achieved 3x-6x improvement in processing time while maintaining performance levels. The system has proven cost-effective, reducing both inference time and overall costs even when accounting for compression overhead, and has been successfully integrated into popular frameworks like LangChain and Prompt Flow.</p>


<h2 class="relative group">Framework 
    <div id="framework" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#framework" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Transformer models derive their capabilities primarily from the attention mechanism, represented by the equation:


$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$</p>
<p>We hypothesized that token importance could be quantified through this attention structure. Our analysis focused specifically on attention vectors before the dot product operation, along the non-softmax axis, as this represents how much attention each token receives.</p>
<p>The initial challenge lay in efficiently processing the high-dimensional attention map space 
 \(R^{L \times H \times N \times N }\) where 
 \(L\) is the number of layers, 
 \(H\) is the number of heads and 
 \(N\) is the number of tokens, which varies depending on the prompt.</p>
<p>We reframed the problem in 3 steps to effectively tackle it:</p>
<ul>
<li>
<p><strong>Layerwise Processing</strong>: Considering one layer at a time, which reduced the target function to


$$ f: \mathbb{R}^{H \times N \times N} \rightarrow [0, 1]^{N} $$</p>
</li>
<li>
<p><strong>Individual Vector Analysis</strong>: As the attention mechanism continuously enhances the attention vectors with contextual information, we hypothesized that each attention vector could be used individually


$$ f: \mathbb{R}^{H \times N} \rightarrow [0, 1], \quad \forall i \in {1, \ldots, N} $$</p>
</li>
<li>
<p><strong>Feature Extraction</strong>: For each attention vector, we extract 
 \(f\) statistical features that capture the key characteristics. This makes the input invariant to number fo tokens and finally leaves us with a problem framed as:


$$ f: \mathbb{R}^{f \times N} \rightarrow [0, 1], \quad \forall i \in {1, \ldots, N} $$</p>
</li>
</ul>
<p>This final formulation served as the basis for our classification model.</p>
<p><strong>Feature Engineering</strong>
<img src="/images/experience/amadeus/FeatureEngineering.png" class="grid-w100" /></p>
<p><strong>Proposed Framework</strong>
<img src="/images/experience/amadeus/FinalPipeline.png" class="grid-w100" /></p>


<h3 class="relative group">Experiments 
    <div id="experiments" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#experiments" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>Our framework required optimization of four key components:</p>
<ol>
<li>
<p>Classification Model</p>
<ul>
<li>After evaluating multiple approaches including Support Vector Machines (with RBF Kernel), Random Forest (100 trees), and a Neural Network (similar to LLMLingua 2&rsquo;s token classification layer), Random Forest performed best.</li>
</ul>
</li>
<li>
<p>Feature Selection</p>
<ul>
<li>We analyzed nine potential features: Mean, Standard Deviation, Median, Median Absolute Deviation (MAD), Self-Attention, Kurtosis, Skewness, Quartile Range Values and Entropy</li>
<li>Through Recursive Feature Elimination, we identified four critical features: MAD, Entropy, Standard Deviation and Self-Attention</li>
</ul>
</li>
<li>
<p>Attention Model</p>
<ul>
<li>Our analysis revealed that fine-tuning played a less crucial role than initially anticipated, as <a href="https://huggingface.co/FacebookAI/xlm-roberta-base" target="_blank">vanilla XLM-RoBERTa</a> showed performance comparable to <a href="https://huggingface.co/microsoft/llmlingua-2-xlm-roberta-large-meetingbank" target="_blank">LLMLingua 2&rsquo;s fine-tuned model</a> through the first five layers. This revealed that raw attention maps inherently contain sufficient information for effective compression, regardless of model fine-tuning.</li>
<li>We ultimately selected the <a href="https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5" target="_blank">GTE model</a> for its practical advantages: support for context lengths up to 8192 tokens and superior performance in our metrics.</li>
</ul>
</li>
<li>
<p>Dataset</p>
<ul>
<li>We utilized the <a href="https://huggingface.co/datasets/microsoft/MeetingBank-LLMCompressed" target="_blank">Microsoft MeetingBank-LLMCompressed dataset</a>, which provided high-quality token-level compression labels.</li>
</ul>
</li>
</ol>
<p><strong>Final Framework</strong></p>
<img src="/images/experience/amadeus/Implementation.png" class="grid-w100" />
<p>Our implemented solution processes input text through the GTE transformer&rsquo;s fifth layer, extracts our four identified features from the attention maps, and feeds these into a Random Forest classifier for token retention prediction. This streamlined pipeline offers an efficient balance between computational overhead and compression effectiveness.</p>


<h2 class="relative group">Results 
    <div id="results" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#results" aria-label="Anchor">#</a>
    </span>        
    
</h2>


<h3 class="relative group">Performance 
    <div id="performance" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#performance" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>We evaluated our model using LongBench, a comprehensive benchmark for testing long-context understanding capabilities. The benchmark consists of:</p>
<ul>
<li><strong>Single-document QA</strong>: Tasks requiring understanding of a single long document</li>
<li><strong>Multi-document QA</strong>: Tasks involving reasoning across multiple documents</li>
<li><strong>Summarization</strong>: Tasks focusing on condensing long documents</li>
</ul>
<p>Our Random Forest approach showed strong performance in single-document QA tasks, often outperforming LLMLingua 2, while remaining competitive in other categories. The benchmark tasks span from 2,000 to 18,000 tokens, providing a robust test of model capabilities across varying context lengths.</p>
<table>
<thead>
<tr>
<th>Task</th>
<th>LLMLingua Performance</th>
<th>RF (ours) Performance</th>
<th>Task Type</th>
<th>Eval Metric</th>
<th>Average Length</th>
</tr>
</thead>
<tbody>
<tr>
<td>Multifield QA</td>
<td>33.72</td>
<td><strong>34.48</strong></td>
<td>Single-doc QA</td>
<td>F1</td>
<td>4,559</td>
</tr>
<tr>
<td>Qasper</td>
<td>31.17</td>
<td><strong>33.86</strong></td>
<td>Single-doc QA</td>
<td>F1</td>
<td>3,619</td>
</tr>
<tr>
<td>Narrative QA</td>
<td><strong>16.34</strong></td>
<td>15.34</td>
<td>Single-doc QA</td>
<td>F1</td>
<td>18,409</td>
</tr>
<tr>
<td>2wikimqa</td>
<td><strong>35.83</strong></td>
<td>34.71</td>
<td>Multi-doc QA</td>
<td>F1</td>
<td>4,887</td>
</tr>
<tr>
<td>Hotpotqa</td>
<td><strong>47.73</strong></td>
<td>44.26</td>
<td>Multi-doc QA</td>
<td>F1</td>
<td>9,151</td>
</tr>
<tr>
<td>MuSiQue</td>
<td><strong>23.41</strong></td>
<td>20.66</td>
<td>Multi-doc QA</td>
<td>F1</td>
<td>11,214</td>
</tr>
<tr>
<td>Multi News</td>
<td>23.73</td>
<td><strong>24.37</strong></td>
<td>Summarization</td>
<td>Rouge-L</td>
<td>2,113</td>
</tr>
<tr>
<td>Gov Report</td>
<td><strong>25.12</strong></td>
<td>22.48</td>
<td>Summarization</td>
<td>Rouge-L</td>
<td>8,734</td>
</tr>
<tr>
<td>QM Sum</td>
<td><strong>21.83</strong></td>
<td>20.26</td>
<td>Summarization</td>
<td>Rouge-L</td>
<td>10,614</td>
</tr>
</tbody>
</table>


<h3 class="relative group">Latency 
    <div id="latency" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#latency" aria-label="Anchor">#</a>
    </span>        
    
</h3>
<p>We compared real-time processing speeds between LLMLingua 2 and the Random Forest method, tested on an Intel Xeon Platinum 8168 CPU. This significant speed difference demonstrates the Random Forest&rsquo;s superior efficiency for CPU-based deployments, making it particularly suitable for real-time applications where GPU access might be limited or cost-prohibitive.</p>
<table>
<thead>
<tr>
<th>Number of Tokens</th>
<th>LLMLingua 2 (s)</th>
<th>RF (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>500 tokens</td>
<td>7.74</td>
<td>1.45</td>
</tr>
<tr>
<td>2000 tokens</td>
<td>8.89</td>
<td>3.58</td>
</tr>
</tbody>
</table>
<p>Our approach offers a resource-efficient solution to prompt compression by using a simple Random Forest classifier instead of fine-tuning large language models. Compared to LLMLingua 2&rsquo;s 355M parameters and additional model layers, our method requires only 74M parameters by utilizing 5 transformer layers. This dramatically reduces both development and inference costs while extending context handling to 8192 tokens, effectively addressing the &ldquo;lost in the middle&rdquo; problem that affects many LLMs.</p>

          
          
          
        </div>
        
        

        
        

          
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_experience\/amadeus\/index.md"
        var oid_likes = "likes_experience\/amadeus\/index.md"
      </script>
      
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
      
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/experience/i3s/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >L1,∞ Convolutional-VAE Projection for DNA Encoding</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
  
  <div class="flex items-center justify-between">

    
    

    
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
</footer>

  </div>
</body>

</html>
